---
layout: page
title: Invited Speakers
subtitle: ParCFD 2025
hero_image:  /img/casaMontejo.webp
hero_height: is-halfheight
hero_darken: true
show_sidebar: false
---

<!-- {% include notification.html message="Site under construction, information will be updated very soon." %} -->

The following renowned experts will join us at ParCFD 2025 to enrich our conference with keynote lectures on various topics of interest to our CFD community.

<h2 id="speaker-1" class="has-text-centered">
    Matthias Möller - Delft University of Technology
</h2>

<img loading="lazy" src="{{ site.baseurl }}/img/moller.webp" alt="Invited Speakers" style="width: 300px; height: auto; display: block; margin: 0 auto"/>

<p class="has-text-justified">
    Matthias Möller is Associate Professor of Numerical Analysis at Delft University of Technology, The Netherlands. He holds a PhD degree in Mathematics from TU Dortmund University and joined TU Delft in 2013. He is currently leading the quantum-CFD lab which is a joined research initiative between TU Delft and Fujitsu Limited, Japan. Matthias’ research focuses on the development of numerical methods for fluid flow applications both on conventional and emerging compute technologies. His particular interest is in finite element and isogeometric analysis as well as lattice Boltzmann methods. He has (co-)authored more than 70 research articles and book chapters and is member of the advisory council of the DLR Quantum Computing Initiative. Matthias is moreover one of the PIs in the TU Delft QAIMS-lab, which focuses on quantum-enhanced AI solutions for sustainable materials and structural designs in Aerospace.
</p>

**Title of Möller's keynote lecture:** *Quantum lattice Boltzmann methods*

**Abstract:**

<p class="has-text-justified">
    <em>Quantum computing (QC) is an emerging compute technology that has the potential to radically change the way we will be solving CFD problems in the future. The potential power of QC stems from the exploitation of quantum mechanical principles, namely, superposition of states, entanglement and quantum parallelism. With properly designed quantum algorithms that fully exploit these properties it will be possible to solve certain types of computational problems up to exponentially faster or with exponentially less memory storage compared to classical counterparts. However, this requires the complete redesign of the solution procedure from scratch rather than a simple "porting" of classical algorithms to quantum computers.</em>
</p>

<p class="has-text-justified">
    <em>In this presentation, I will discuss the current state of the art of quantum lattice Boltzmann methods (QLBM). In particular, I will present different approaches to store ("encode") grid data efficiently in the quantum register and perform the computational steps of the LBM - streaming, collision, and boundary treatment - as efficiently executable quantum circuits. The main challenge lies in designing the data encoding scheme and the quantum circuits in a way that exploits quantum mechanical principles, delivers (at least theoretically) a speed up over classical LBM, and is implementable on (future) quantum computers. The next challenge lies in the efficient extraction of meaningful information via measurement, which is the only way to read out data from a quantum computer. Since the measurement-based read-out of full flow fields is very inefficient, we have developed a quantum variant of the widely-used momentum exchange method (MEM) that calculates the forces acting on objects from which user-defined quantities of interest like the drag or lift coefficient can be calculated in a post processing step.</em>
</p>

<p class="has-text-justified">
    <em>Next to discussing the algorithmic building blocks of quantum lattice Boltzmann methods from a conceptual perspective, I will present an end-to-end quantum LBM application and first numerical results in 2D and 3D obtained with our open-source QLBM software on quantum computer simulators.</em>
</p>

---

<h2 id="speaker-2" class="has-text-centered">
    Dr. Héctor Benítez Pérez - UNAM
</h2>

<img loading="lazy" src="{{ site.baseurl }}/img/DrHectorBenitezPerez.webp" alt="Invited Speakers" style="width: 300px; height: auto; display: block; margin: 0 auto"/>

<p class="has-text-justified">
    Dr. Héctor Benítez Pérez graduated with honors in Mechanical and Electrical Engineering from UNAM and obtained his PhD from the University of Sheffield in the Department of Automatic Control and Systems Engineering. He was director of IIMAS and currently heads the DGTIC (General Directorate of Information and Communication Technologies) at UNAM. As a researcher, he has extensive scientific output and is a member of the National System of Researchers. He has served on the University Council, the Academic Council of the Area of Physical and Mathematical Sciences and Engineering, as well as on other university committees and commissions. He is a member of the Mexican Academy of Sciences and the Mexican Academy of Engineering.
    <br/>
    <br/>
    In academic matters, he stands out for the creation of the Bachelor's Degree in Data Science and the High-Performance Computing specialty and has participated in numerous research projects and technological developments, especially in neural networks and data science. Recognized as one of the most cited academics in the field of computing, he received recognition for outstanding contribution in the ELSEVIER Journal of Engineering Application of Artificial Intelligence and the ELSEVIER Journal of the Franklin Institute. In 2024, he was honored with the Wolfram Innovator Award.
    <br/>
    <br/>
    As Director of Computing and Information and Communication Technologies at UNAM, he has strengthened ICT governance and cybersecurity, consolidated cloud services, virtual desktops, advanced electronic signature systems, and a digital vault, and led efforts to establish a federated system for supercomputing with the GRID UNAM initiative.
    <br/>
    <br/>
    He has promoted the introduction of quantum computing through simulator testing with the participation of the research community; he has promoted courses, workshops, and diploma programs on innovative technology topics; he has systematized school administration processes for graduation; and he has created publication spaces for technical reports on ICT projects and services. He has spearheaded Macrotraining in Artificial Intelligence to promote talent development and academic collaboration among students at universities and academic institutions in Latin America and the Caribbean, and has participated in the organization of forums, workshops, and meetings to promote research on Artificial Intelligence in Mexico. He also contributes to various academic networks to support the development of high-value ICTs in higher education institutions.
</p>

**Title of Benítez's keynote lecture:** *High Performance Computing at UNAM: New Paradigm* 

<!-- **Abstract:**

<p class="has-text-justified">
    <em>Quantum computing (QC) is an emerging compute technology that has the potential to radically change the way we will be solving CFD problems in the future. The potential power of QC stems from the exploitation of quantum mechanical principles, namely, superposition of states, entanglement and quantum parallelism. With properly designed quantum algorithms that fully exploit these properties it will be possible to solve certain types of computational problems up to exponentially faster or with exponentially less memory storage compared to classical counterparts. However, this requires the complete redesign of the solution procedure from scratch rather than a simple "porting" of classical algorithms to quantum computers.</em>
</p>

<p class="has-text-justified">
    <em>In this presentation, I will discuss the current state of the art of quantum lattice Boltzmann methods (QLBM). In particular, I will present different approaches to store ("encode") grid data efficiently in the quantum register and perform the computational steps of the LBM - streaming, collision, and boundary treatment - as efficiently executable quantum circuits. The main challenge lies in designing the data encoding scheme and the quantum circuits in a way that exploits quantum mechanical principles, delivers (at least theoretically) a speed up over classical LBM, and is implementable on (future) quantum computers. The next challenge lies in the efficient extraction of meaningful information via measurement, which is the only way to read out data from a quantum computer. Since the measurement-based read-out of full flow fields is very inefficient, we have developed a quantum variant of the widely-used momentum exchange method (MEM) that calculates the forces acting on objects from which user-defined quantities of interest like the drag or lift coefficient can be calculated in a post processing step.</em>
</p>

<p class="has-text-justified">
    <em>Next to discussing the algorithmic building blocks of quantum lattice Boltzmann methods from a conceptual perspective, I will present an end-to-end quantum LBM application and first numerical results in 2D and 3D obtained with our open-source QLBM software on quantum computer simulators.</em>
</p> -->

---

<h2 id="speaker-3" class="has-text-centered">
    Dr. Matthias Meinke - RWTH Aachen University
</h2>

<img loading="lazy" src="{{ site.baseurl }}/img/matthias.webp" alt="Invited Speakers" style="width: 300px; height: auto; display: block; margin: 0 auto"/>

<p class="has-text-justified">
    Dr. Matthias Meinke earned his Diploma in Aerospace Engineering from RWTH Aachen University, Germany. Following this, he joined the Institute of Aerodynamics at RWTH Aachen University as a research assistant under the guidance of Prof. E. Krause. In 1993, he completed his Ph.D., presenting a dissertation focused on the Numerical Solution of the Navier-Stokes Equations for Unsteady Flows using the Multigrid Method.
    <br/>
    <br/>
    Afterward, Dr. Meinke took on the role of head of the CFD department at the Institute of Aerodynamics and began teaching Computational Fluid Dynamics in both Bachelor’s and Master’s programs at RWTH Aachen University. He has extensive experience in various fields including aerodynamics, turbulence, aeroacoustics, turbomachinery, multiphase flows, and the development of advanced numerical methods.
    <br/>
    <br/>
    For many years, Dr. Meinke and his team have been developing a multiphysics software framework specifically designed for high-performance computing systems. This framework is utilized in numerous national and European projects. To date, he has published over 180 peer-reviewed journal articles.
</p>

<strong>Title of Meinke's keynote lecture:</strong> <em>Efficient Coupled Multiphysics Simulations based on Hierarchical Cartesian Meshes</em> 

<strong>Abstract:</strong>


<p class="has-text-justified">
    <em>Multiphysics problems often require coupled solution methods across distinct solvers, posing challenges in efficiency and scalability, in particular for temporally evolving domains. This presentation presents a numerical framework for such coupled problems, leveraging hierarchical Cartesian meshes with adaptive mesh refinement (AMR) and dynamic load balancing to ensure computational efficiency.
    <br/>
    <br/>
    The proposed methods employ a shared base-level hierarchical Cartesian mesh, while allowing solver-specific refinement, enabling tailored resolution for each physics domain. We demonstrate the approach’s versatility through applications in conjugate heat transfer, aeroacoustics, and spray modeling. Crucially, dynamic load balancing proves advantageous not only for adaptive meshes but also for static ones, preventing memory overflow in individual ranks and achieving high parallel efficiency. Our results show that the coupled scheme achieves robust scalability, addressing key bottlenecks in multiphysics simulations with moving geometries.</em>
</p>

---

<h1>
    Keynote
</h1>
<h2 id="speaker-4" class="has-text-centered">
    Dr. Simone Marras - New Jersey Institute of Technology
</h2>
<img loading="lazy" src="{{ site.baseurl }}/img/simone.webp" alt="Invited Speakers" style="width: 300px; height: auto; display: block; margin: 0 auto"/>
<p class="has-text-justified">
    Simone Marras is Associate Professor of Fluid Dynamics at New Jersey Institute of Technology. He has been working in scientific computing and computational fluid dynamics for fifteen years and he enjoys writing open source software to solve PDEs.
</p>
<strong>Title of Marras's keynote lecture:</strong> <em>The Evolution of Environmental Modeling in the Era of High-Performance Computing</em> 
<br>
<br>
<strong>Abstract:</strong>
<p class="has-text-justified">
    <em>
        The past two decades have witnessed a profound transformation in numerical weather prediction, climate, and ocean modeling, largely driven by the widespread availability of massively parallel computing resources. This presentation will explore the key advancements that have propelled this evolution, the underlying factors that necessitated these changes, and the enduring computational and numerical challenges as we transition into and beyond the exascale computing era.
        A central focus will be on the numerical modeling of natural hazards, specifically tropical cyclones and tsunamis. We will identify the computational and numerical requirements essential for their accurate and effective simulation.
        <br>
        <br>
        Regarding tropical cyclones, which pose significant societal and economic threats, advancements in numerical techniques have led to substantial improve-
        ments in track forecasting. However, the mechanisms governing rapid intensification (RI) remain an area of active research. This talk will demonstrate how recent progress in very high-resolution large eddy simulations is enhancing our understanding of the fundamental processes that control RI dynamics.
        With respect to tsunami modeling, the discussion will center on simulating their interaction with coastal features, particularly within the context of natural protection strategies.
        <br>
        <br>
        Finally, while exascale computing now enables simulations at resolutions previously unattainable, the emerging field of quantum computing is also exploring applications in fluid dynamics. We will consider the potential for these advanced computational paradigms to significantly reduce the time required for large-scale simulations in the future.
    </em>
</p>
